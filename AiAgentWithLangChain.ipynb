{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOs6n/q+70lX0aLWIf8qVuu",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/neel26desai/ai_agents/blob/main/AiAgentWithLangChain.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JMJezo2dsKBf"
      },
      "outputs": [],
      "source": [
        "!pip install -qU langchain openai google-search-results wikipedia sqlalchemy"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata"
      ],
      "metadata": {
        "id": "7K-O_bhtuvbz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#this will promptyou to put your openai_api_key\n",
        "from getpass import getpass\n",
        "\n",
        "OPENAI_API_KEY = getpass()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pYQyBMgA1chd",
        "outputId": "6b65d9bf-d743-4b72-a33d-3def12071c36"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "··········\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#create a gent using open AI's got 3.5\n",
        "from langchain import OpenAI\n",
        "\n",
        "llm = OpenAI(\n",
        "    openai_api_key=OPENAI_API_KEY,\n",
        "    temperature=0\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EW7Ojk6mvfb-",
        "outputId": "c322bac1-1bf6-4096-fa87-33309172129f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/langchain_core/_api/deprecation.py:117: LangChainDeprecationWarning: The class `langchain_community.llms.openai.OpenAI` was deprecated in langchain-community 0.0.10 and will be removed in 0.2.0. An updated version of the class exists in the langchain-openai package and should be used instead. To use it run `pip install -U langchain-openai` and import as `from langchain_openai import OpenAI`.\n",
            "  warn_deprecated(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#for each request we will be counting the number of tokesn used\n",
        "from langchain.callbacks import get_openai_callback\n",
        "def count_tokens(agent, query):\n",
        "    with get_openai_callback() as cb:\n",
        "        result = agent(query)\n",
        "        print(f'Spent a total of {cb.total_tokens} tokens')\n",
        "\n",
        "    return result"
      ],
      "metadata": {
        "id": "I73dnsrJvfZX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "count_tokens(llm, \"What is the capital of USA\") #testing the function"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "KScUwi_34RUC",
        "outputId": "17667c63-2bcf-456c-9a43-5826ef70659d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Spent a total of 17 tokens\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\n\\nThe capital of USA is Washington, D.C.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Creating a database\n",
        "We will be creating a dummy database for saving people's weight and heights at different point in time. And We will use this table for testing out zero shot classifing agent."
      ],
      "metadata": {
        "id": "Dok-5felwnA6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sqlalchemy import MetaData\n",
        "from sqlalchemy import Column, Integer, Float, String, Date, Table\n",
        "from datetime import datetime\n",
        "\n",
        "metadata_obj = MetaData()\n",
        "\n",
        "people_measurements = Table(\n",
        "    \"people_measurements\",\n",
        "    metadata_obj,\n",
        "    Column(\"obs_id\", Integer, primary_key=True),\n",
        "    Column(\"person_id\", String(10), nullable=False),\n",
        "    Column(\"weight\", Float, nullable=False),\n",
        "    Column(\"height\", Float, nullable=False),\n",
        "    Column(\"date\", Date, nullable=False),\n",
        ")\n",
        "\n",
        "# Dummy observations\n",
        "observations = [\n",
        "    [1,'Person1', 70.5, 175.3, datetime(2023, 1, 1)],\n",
        "    [2,'Person1', 71.0, 175.3, datetime(2023, 1, 2)],\n",
        "    [3,'Person1', 70.8, 175.3, datetime(2023, 1, 3)],\n",
        "    [4,'Person1', 71.2, 175.3, datetime(2023, 1, 4)],\n",
        "    [5,'Person1', 71.0, 175.3, datetime(2023, 1, 5)],\n",
        "    [6,'Person2', 65.0, 180.5, datetime(2023, 1, 1)],\n",
        "    [7,'Person2', 65.3, 180.5, datetime(2023, 1, 2)],\n",
        "    [8,'Person2', 64.8, 180.5, datetime(2023, 1, 3)],\n",
        "    [9,'Person2', 65.2, 180.5, datetime(2023, 1, 4)],\n",
        "    [10,'Person2', 64.9, 180.5, datetime(2023, 1, 5)],\n",
        "]"
      ],
      "metadata": {
        "id": "2KIuPxpsvfWz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "uTNwbIyN22tD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sqlalchemy import create_engine\n",
        "\n",
        "engine = create_engine(\"sqlite:///:memory:\")\n",
        "metadata_obj.create_all(engine)"
      ],
      "metadata": {
        "id": "pY3tFygdvfUK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sqlalchemy import insert\n",
        "\n",
        "def insert_people_measurements(obs):\n",
        "    stmt = insert(people_measurements).values(\n",
        "        obs_id=obs[0],\n",
        "        person_id=obs[1],\n",
        "        weight=obs[2],\n",
        "        height=obs[3],\n",
        "        date=obs[4]\n",
        "    )\n",
        "\n",
        "    with engine.begin() as conn:\n",
        "        conn.execute(stmt)\n"
      ],
      "metadata": {
        "id": "sqR-kxcmvfRk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for obs in observations:\n",
        "    insert_people_measurements(obs)"
      ],
      "metadata": {
        "id": "YcJ9fqEKvfO9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install langchain_experimental -qU"
      ],
      "metadata": {
        "id": "LeDbpqMtvfMH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.utilities import SQLDatabase\n",
        "from langchain_experimental.sql import SQLDatabaseChain\n",
        "\n",
        "db = SQLDatabase(engine)\n",
        "sql_chain = SQLDatabaseChain(llm=llm, database=db, verbose=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TCYCc-CNvfJq",
        "outputId": "8b78fd81-6a0b-409c-be09-7a0f4faf9623"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/langchain_experimental/sql/base.py:76: UserWarning: Directly instantiating an SQLDatabaseChain with an llm is deprecated. Please instantiate with llm_chain argument or using the from_llm class method.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Zero Shot React"
      ],
      "metadata": {
        "id": "sdUcwpW2z2vE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.agents import create_sql_agent\n",
        "from langchain.agents.agent_toolkits import SQLDatabaseToolkit\n",
        "from langchain.agents.agent_types import AgentType\n",
        "\n",
        "agent_executor = create_sql_agent(\n",
        "    llm=llm,\n",
        "    toolkit=SQLDatabaseToolkit(db=db, llm=llm),\n",
        "    verbose=True,\n",
        "    agent_type=AgentType.ZERO_SHOT_REACT_DESCRIPTION,\n",
        "    max_iterations=3\n",
        ")"
      ],
      "metadata": {
        "id": "f7zBG4fbz0Es"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result = count_tokens(\n",
        "    agent_executor,\n",
        "   \"What is the average weight for Person1 on 2023-01-01\"\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0BpC1ymPz0BC",
        "outputId": "72fe5be3-75c7-4539-a919-d4da9a8ffaa9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new SQL Agent Executor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3m I need to query the database for the average weight of Person1 on a specific date.\n",
            "Action: sql_db_query\n",
            "Action Input: SELECT AVG(weight) FROM Person1 WHERE date = '2023-01-01'\u001b[0m\u001b[36;1m\u001b[1;3mError: (sqlite3.OperationalError) no such table: Person1\n",
            "[SQL: SELECT AVG(weight) FROM Person1 WHERE date = '2023-01-01']\n",
            "(Background on this error at: https://sqlalche.me/e/20/e3q8)\u001b[0m\u001b[32;1m\u001b[1;3mI need to use sql_db_list_tables to see if Person1 table exists.\n",
            "Action: sql_db_list_tables\n",
            "Action Input: \"\"\u001b[0m\u001b[38;5;200m\u001b[1;3mpeople_measurements\u001b[0m\u001b[32;1m\u001b[1;3mI need to use sql_db_schema to see the schema and sample rows for the people_measurements table.\n",
            "Action: sql_db_schema\n",
            "Action Input: people_measurements\u001b[0m\u001b[33;1m\u001b[1;3m\n",
            "CREATE TABLE people_measurements (\n",
            "\tobs_id INTEGER NOT NULL, \n",
            "\tperson_id VARCHAR(10) NOT NULL, \n",
            "\tweight FLOAT NOT NULL, \n",
            "\theight FLOAT NOT NULL, \n",
            "\tdate DATE NOT NULL, \n",
            "\tPRIMARY KEY (obs_id)\n",
            ")\n",
            "\n",
            "/*\n",
            "3 rows from people_measurements table:\n",
            "obs_id\tperson_id\tweight\theight\tdate\n",
            "1\tPerson1\t70.5\t175.3\t2023-01-01\n",
            "2\tPerson1\t71.0\t175.3\t2023-01-02\n",
            "3\tPerson1\t70.8\t175.3\t2023-01-03\n",
            "*/\u001b[0m\u001b[32;1m\u001b[1;3m\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "Spent a total of 0 tokens\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "agent_executor.agent"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XWdzliwQzz9p",
        "outputId": "9d237681-282c-4989-8224-ea13f2484e77"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RunnableAgent(runnable=RunnableAssign(mapper={\n",
              "  agent_scratchpad: RunnableLambda(lambda x: format_log_to_str(x['intermediate_steps']))\n",
              "})\n",
              "| PromptTemplate(input_variables=['agent_scratchpad', 'input'], partial_variables={'tools': \"sql_db_query: Input to this tool is a detailed and correct SQL query, output is a result from the database. If the query is not correct, an error message will be returned. If an error is returned, rewrite the query, check the query, and try again. If you encounter an issue with Unknown column 'xxxx' in 'field list', use sql_db_schema to query the correct table fields.\\nsql_db_schema: Input to this tool is a comma-separated list of tables, output is the schema and sample rows for those tables. Be sure that the tables actually exist by calling sql_db_list_tables first! Example Input: table1, table2, table3\\nsql_db_list_tables: Input is an empty string, output is a comma-separated list of tables in the database.\\nsql_db_query_checker: Use this tool to double check if your query is correct before executing it. Always use this tool before executing a query with sql_db_query!\", 'tool_names': 'sql_db_query, sql_db_schema, sql_db_list_tables, sql_db_query_checker'}, template='Answer the following questions as best you can. You have access to the following tools:\\n\\n{tools}\\n\\nUse the following format:\\n\\nQuestion: the input question you must answer\\nThought: you should always think about what to do\\nAction: the action to take, should be one of [{tool_names}]\\nAction Input: the input to the action\\nObservation: the result of the action\\n... (this Thought/Action/Action Input/Observation can repeat N times)\\nThought: I now know the final answer\\nFinal Answer: the final answer to the original input question\\n\\nBegin!\\n\\nQuestion: {input}\\nThought:{agent_scratchpad}')\n",
              "| RunnableBinding(bound=SQLDatabaseChain(verbose=True, llm_chain=LLMChain(prompt=PromptTemplate(input_variables=['input', 'table_info', 'top_k'], template='You are a SQLite expert. Given an input question, first create a syntactically correct SQLite query to run, then look at the results of the query and return the answer to the input question.\\nUnless the user specifies in the question a specific number of examples to obtain, query for at most {top_k} results using the LIMIT clause as per SQLite. You can order the results to return the most informative data in the database.\\nNever query for all columns from a table. You must query only the columns that are needed to answer the question. Wrap each column name in double quotes (\") to denote them as delimited identifiers.\\nPay attention to use only the column names you can see in the tables below. Be careful to not query for columns that do not exist. Also, pay attention to which column is in which table.\\nPay attention to use date(\\'now\\') function to get the current date, if the question involves \"today\".\\n\\nUse the following format:\\n\\nQuestion: Question here\\nSQLQuery: SQL Query to run\\nSQLResult: Result of the SQLQuery\\nAnswer: Final answer here\\n\\nOnly use the following tables:\\n{table_info}\\n\\nQuestion: {input}'), llm=OpenAI(client=<openai.resources.completions.Completions object at 0x7a155ca377c0>, async_client=<openai.resources.completions.AsyncCompletions object at 0x7a155ca6feb0>, temperature=0.0, openai_api_key='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', openai_proxy='')), llm=OpenAI(client=<openai.resources.completions.Completions object at 0x7a155ca377c0>, async_client=<openai.resources.completions.AsyncCompletions object at 0x7a155ca6feb0>, temperature=0.0, openai_api_key='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', openai_proxy=''), database=<langchain_community.utilities.sql_database.SQLDatabase object at 0x7a1572e62ce0>), kwargs={'stop': ['\\nObservation']})\n",
              "| ReActSingleInputOutputParser(), input_keys_arg=['input'], return_keys_arg=['output'], stream_runnable=True)"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Conversational React"
      ],
      "metadata": {
        "id": "deEbK1Mt7hGz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.agents import load_tools\n",
        "\n",
        "tools = load_tools(\n",
        "    [\"llm-math\"],\n",
        "    llm=llm\n",
        ")\n"
      ],
      "metadata": {
        "id": "BYRKoghm7g2O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.memory import ConversationBufferMemory\n",
        "\n",
        "memory = ConversationBufferMemory(memory_key=\"chat_history\")"
      ],
      "metadata": {
        "id": "OhZvVmuZzz6z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.agents import initialize_agent\n",
        "\n",
        "conversational_agent = initialize_agent(\n",
        "    agent=AgentType.CONVERSATIONAL_REACT_DESCRIPTION,\n",
        "    tools=tools,\n",
        "    llm=llm,\n",
        "    verbose=True,\n",
        "    max_iterations=3,\n",
        "    memory=memory,\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9iH9tX7Nzz3I",
        "outputId": "1bed7d16-d62f-42f5-ada9-f9f1ae44ecf8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/langchain_core/_api/deprecation.py:117: LangChainDeprecationWarning: The function `initialize_agent` was deprecated in LangChain 0.1.0 and will be removed in 0.2.0. Use Use new agent constructor methods like create_react_agent, create_json_agent, create_structured_chat_agent, etc. instead.\n",
            "  warn_deprecated(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "result = count_tokens(\n",
        "    conversational_agent,\n",
        "    \"What is the product of all numbers from 0 to 5\"\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7DV9GaWNzz0A",
        "outputId": "61207ec3-cf03-42d4-e1bd-9f3dddf7c04e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3mThought: Do I need to use a tool? Yes\n",
            "Action: Calculator\n",
            "Action Input: 0*1*2*3*4*5\u001b[0m\n",
            "Observation: \u001b[36;1m\u001b[1;3mAnswer: 0\u001b[0m\n",
            "Thought:\u001b[32;1m\u001b[1;3m Do I need to use a tool? No\n",
            "AI: The product of all numbers from 0 to 5 is 0.\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "Spent a total of 1097 tokens\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "result = count_tokens(\n",
        "    conversational_agent,\n",
        "    \"If we perform the same operation but this time on numbers beteern 1 to 5?\"\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dME5swcQzzwX",
        "outputId": "668d226e-0f28-4adf-e6c4-ac2affe3944f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3mThought: Do I need to use a tool? Yes\n",
            "Action: Calculator\n",
            "Action Input: 1*2*3*4*5\u001b[0m\n",
            "Observation: \u001b[36;1m\u001b[1;3mAnswer: 120\u001b[0m\n",
            "Thought:\u001b[32;1m\u001b[1;3m Do I need to use a tool? No\n",
            "AI: The product of all numbers from 1 to 5 is 120.\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "Spent a total of 1165 tokens\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# React Docstore"
      ],
      "metadata": {
        "id": "5dQIurgo8qjW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain import Wikipedia\n",
        "from langchain.agents.react.base import DocstoreExplorer, Tool\n",
        "\n",
        "\n",
        "docstore=DocstoreExplorer(Wikipedia())\n",
        "tools = [\n",
        "    Tool(\n",
        "        name=\"Search\",\n",
        "        func=docstore.search,\n",
        "        description='search wikipedia'\n",
        "    ),\n",
        "    Tool(\n",
        "        name=\"Lookup\",\n",
        "        func=docstore.lookup,\n",
        "        description='lookup a term in wikipedia'\n",
        "    )\n",
        "]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ajS34i0Jzztx",
        "outputId": "ea672193-54e3-4670-bd5e-86b7092ba31b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/langchain_core/_api/deprecation.py:117: LangChainDeprecationWarning: The class `langchain.agents.react.base.DocstoreExplorer` was deprecated in langchain 0.1.0 and will be removed in 0.2.0\n",
            "  warn_deprecated(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "docstore_agent = initialize_agent(\n",
        "    tools,\n",
        "    llm,\n",
        "    agent=\"react-docstore\",\n",
        "    verbose=True,\n",
        "    max_iterations=3\n",
        ")"
      ],
      "metadata": {
        "id": "FNLnZNHBzzpm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "count_tokens(docstore_agent, \"What were Julis Ceaser's last words?\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EFUKD_H1zzmd",
        "outputId": "774ab094-506e-4020-b13a-47567403691d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3mThought: I need to search Julius Caesar and find his last words.\n",
            "Action: Search[Julius Caesar]\u001b[0m\n",
            "Observation: \u001b[36;1m\u001b[1;3mCould not find [Julius Caesar]. Similar: ['Julius Caesar', 'Assassination of Julius Caesar', 'Julius Caesar (play)', 'Augustus', 'Last words of Julius Caesar', 'Tiberius', \"William Shakespeare's Julius Caesar\", 'Gaius Julius Caesar (governor of Asia)', 'The Death of Julius Caesar (Camuccini)', 'Germanicus']\u001b[0m\n",
            "Thought:\u001b[32;1m\u001b[1;3m I can search \"Last words of Julius Caesar\" instead.\n",
            "Action: Search[Last words of Julius Caesar]\u001b[0m\n",
            "Observation: \u001b[36;1m\u001b[1;3mThe last words of the Roman dictator Julius Caesar are disputed. Ancient chroniclers reported a variety of phrases and post-classical writers have elaborated on the phrases and their interpretation. The two most common theories – prevalent as early as the second century AD – are that he said nothing or that he said, in Greek, καὶ σύ, τέκνον (kaì sý, téknon; 'you too, child').William Shakespeare's Latin rendition of this phrase, Et tu, Brute? ('You too, Brutus?'), in the play Julius Caesar, is better known in modern culture, but is not found in ancient sources.\u001b[0m\n",
            "Thought:\u001b[32;1m\u001b[1;3m The last words of Julius Caesar are disputed, but the most common theories are that he said nothing or \"You too, child\" in Greek. So the answer is either nothing or \"You too, child\" in Greek.\n",
            "Action: Finish[nothing or \"You too, child\" in Greek]\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "Spent a total of 4607 tokens\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'input': \"What were Julis Ceaser's last words?\",\n",
              " 'output': 'nothing or \"You too, child\" in Greek'}"
            ]
          },
          "metadata": {},
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Self Ask with Chain"
      ],
      "metadata": {
        "id": "0LvMfuOr9DuJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain import OpenAI, SerpAPIWrapper\n",
        "from langchain.agents import initialize_agent, Tool\n",
        "\n",
        "search = SerpAPIWrapper(serpapi_api_key=userdata.get(\"serp_key\"))\n",
        "tools = [\n",
        "    Tool(\n",
        "        name=\"Intermediate Answer\",\n",
        "        func=search.run,\n",
        "        description='google search'\n",
        "    )\n",
        "]\n",
        "\n",
        "self_ask_with_search = initialize_agent(tools, llm, agent=\"self-ask-with-search\", verbose=True)\n"
      ],
      "metadata": {
        "id": "4k5DrrR0zzjZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(self_ask_with_search.agent.llm_chain.prompt.template)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q_Piic7V-WLN",
        "outputId": "149df925-99ce-486b-ee39-ae51a7832517"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Question: Who lived longer, Muhammad Ali or Alan Turing?\n",
            "Are follow up questions needed here: Yes.\n",
            "Follow up: How old was Muhammad Ali when he died?\n",
            "Intermediate answer: Muhammad Ali was 74 years old when he died.\n",
            "Follow up: How old was Alan Turing when he died?\n",
            "Intermediate answer: Alan Turing was 41 years old when he died.\n",
            "So the final answer is: Muhammad Ali\n",
            "\n",
            "Question: When was the founder of craigslist born?\n",
            "Are follow up questions needed here: Yes.\n",
            "Follow up: Who was the founder of craigslist?\n",
            "Intermediate answer: Craigslist was founded by Craig Newmark.\n",
            "Follow up: When was Craig Newmark born?\n",
            "Intermediate answer: Craig Newmark was born on December 6, 1952.\n",
            "So the final answer is: December 6, 1952\n",
            "\n",
            "Question: Who was the maternal grandfather of George Washington?\n",
            "Are follow up questions needed here: Yes.\n",
            "Follow up: Who was the mother of George Washington?\n",
            "Intermediate answer: The mother of George Washington was Mary Ball Washington.\n",
            "Follow up: Who was the father of Mary Ball Washington?\n",
            "Intermediate answer: The father of Mary Ball Washington was Joseph Ball.\n",
            "So the final answer is: Joseph Ball\n",
            "\n",
            "Question: Are both the directors of Jaws and Casino Royale from the same country?\n",
            "Are follow up questions needed here: Yes.\n",
            "Follow up: Who is the director of Jaws?\n",
            "Intermediate answer: The director of Jaws is Steven Spielberg.\n",
            "Follow up: Where is Steven Spielberg from?\n",
            "Intermediate answer: The United States.\n",
            "Follow up: Who is the director of Casino Royale?\n",
            "Intermediate answer: The director of Casino Royale is Martin Campbell.\n",
            "Follow up: Where is Martin Campbell from?\n",
            "Intermediate answer: New Zealand.\n",
            "So the final answer is: No\n",
            "\n",
            "Question: {input}\n",
            "Are followup questions needed here:{agent_scratchpad}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "count_tokens(self_ask_with_search, \"Who discvored the first computer?\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q36TJITO-ao4",
        "outputId": "26c52938-1a1c-412b-9d18-88e664950077"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3m Yes.\n",
            "Follow up: What was the name of the first computer?\u001b[0m\n",
            "Intermediate answer: \u001b[36;1m\u001b[1;3mElectronic Numerical Integrator and Computer\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3mFollow up: Who invented the Electronic Numerical Integrator and Computer?\u001b[0m\n",
            "Intermediate answer: \u001b[36;1m\u001b[1;3m['ENIAC was the first programmable, electronic, general-purpose digital computer, completed in 1945. Other computers had some of these features, but ENIAC was the first to have them all. It was Turing-complete and able to solve \"a large class of numerical problems\" through reprogramming.', 'ENIAC type: Computer.', 'ENIAC entity_type: kp3_verticals.', 'ENIAC kgmid: /m/0hk_b.', 'ENIAC date_introduced: February 15, 1946.', 'ENIAC built_founded: 1945.', 'ENIAC phmc_dedicated: Thursday, June 15, 2000.', 'ENIAC (/ˈɛniæk/; Electronic Numerical Integrator and Computer) was the first programmable, electronic, general-purpose digital computer, completed in 1945.', 'ENIAC, the first programmable general-purpose electronic digital computer, built during World War II by the United States and completed in ...', 'Designed by John Mauchly and J. Presper Eckert, ENIAC was the fastest computational device of its time, able to do 5,000 additions per second, ...', 'Originally announced on February 14, 1946, the Electronic Numerical Integrator and Computer (ENIAC), was the first general-purpose electronic computer.', 'John William Mauchly and J. Presper Eckert are the scientists credited with the invention of the Electronic Numerical Integrator and Computer (ENIAC), ...', 'The Electronic Numerical Integrator and Computer, or ENIAC, was the first programmable electronic computer. Learn more about this enormous machine and ...', 'ENIACIn 1942, physicist John Mauchly proposed an all-electronic calculating machine. The U.S. Army, meanwhile, needed to calculate complex wartime ...', 'Presper Eckert and John W. Mauchly were the only ones who had a hand in its development. Invented in 1945, the Electronic Numerical Integrator ...', 'John Mauchly co-invented the first practical electronic digital computer. ENIAC, the Electronic Numerical Integrator and Computer, ...', 'ENIAC stands for Electronic Numerical Integrator and Computer. John Mauchly and J. Presper Eckert built the machine at the University of Pennsylvania at the ...']\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3mFollow up: Who is credited with the invention of the ENIAC?\u001b[0m\n",
            "Intermediate answer: \u001b[36;1m\u001b[1;3m['ENIAC was the first programmable, electronic, general-purpose digital computer, completed in 1945. Other computers had some of these features, but ENIAC was the first to have them all. It was Turing-complete and able to solve \"a large class of numerical problems\" through reprogramming.', 'ENIAC type: Computer.', 'ENIAC entity_type: kp3_verticals.', 'ENIAC kgmid: /m/0hk_b.', 'ENIAC date_introduced: February 15, 1946.', 'ENIAC built_founded: 1945.', 'ENIAC phmc_dedicated: Thursday, June 15, 2000.', 'ENIAC, the first programmable general-purpose electronic digital computer, built during World War II by the United States.', \"ENIAC was designed by John Mauchly and J. Presper Eckert to calculate artillery firing tables for the United States Army's Ballistic Research Laboratory (which ...\", 'Designed by John Mauchly and J. Presper Eckert, ENIAC was the fastest computational device of its time, able to do 5,000 additions per second, ...', 'The Inventors: John W ...', 'John William Mauchly and J. Presper Eckert are the scientists credited with the invention of the Electronic Numerical Integrator and Computer (ENIAC), ...', 'Who Invented the ENIAC? On May 31, 1943, the military commission for the new computer began with the partnership of John Mauchly and John ...', 'John Ambrose Fleming Invents the Vacuum Tube, Beginning Electronics: The development of digital computers, including the ENIAC, was enabled by the invention of ...', 'John Mauchly co-invented the first practical electronic digital computer. ENIAC, the Electronic Numerical Integrator and Computer, ...', \"John Mauchly and J. Presper Eckert built the machine at the University of Pennsylvania at the behest of the U.S. military. Mauchly had attracted the army's ...\", 'It was designed and invented by John Presper Eckert and John ... Although it was completed at the end of World War II, the ENIAC was created to ...']\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3mSo the final answer is: John Mauchly and J. Presper Eckert\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "Spent a total of 3138 tokens\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'input': 'Who discvored the first computer?',\n",
              " 'output': 'John Mauchly and J. Presper Eckert'}"
            ]
          },
          "metadata": {},
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Reference\n",
        "1. https://github.com/pinecone-io/examples/blob/master/learn/generation/langchain/handbook/06-langchain-agents.ipynb"
      ],
      "metadata": {
        "id": "Ti_yAFgBuv-7"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "4B_Gl4gCuz1R"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}